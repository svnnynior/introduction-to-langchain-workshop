{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/svnnynior/introduction-to-langchain-workshop/blob/main/th_pycon_langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_cq1IsWCawQ"
      },
      "source": [
        "# Introduction to Langchain\n",
        "\n",
        "LangChain is a framework for developing applications powered by language models\n",
        "\n",
        "- GitHub: https://github.com/langchain-ai/langchain\n",
        "- Docs: https://python.langchain.com/docs/get_started\n",
        "\n",
        "## Outlines\n",
        "1. Main components -- Model, Prompt Template, Output Parser\n",
        "2. Chains\n",
        "3. Memory\n",
        "4. Retriever (RAG)\n",
        "5. Evaluation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eitV0BpiDiWE"
      },
      "source": [
        "## 0. Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nDMgy3hjqOki",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f1ae608-f7c8-43ef-98f1-0e0301739ce6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting langchain==0.0.349\n",
            "  Using cached langchain-0.0.349-py3-none-any.whl (808 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.349) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.349) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.349) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.349) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.349) (0.6.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.349) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.349) (0.0.1)\n",
            "Requirement already satisfied: langchain-core<0.1,>=0.0.13 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.349) (0.0.13)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.349) (0.0.69)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.349) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.349) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.349) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.349) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.349) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.349) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.349) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.349) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.349) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.349) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.349) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.349) (2.4)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.1,>=0.0.13->langchain==0.0.349) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.1,>=0.0.13->langchain==0.0.349) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.349) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.349) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.349) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.349) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.349) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.349) (3.0.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.1,>=0.0.13->langchain==0.0.349) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.1,>=0.0.13->langchain==0.0.349) (1.2.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.349) (1.0.0)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: langchain\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.0.350\n",
            "    Uninstalling langchain-0.0.350:\n",
            "      Successfully uninstalled langchain-0.0.350\n",
            "Successfully installed langchain-0.0.349\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain==0.0.349"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOAGAoxEmZBy"
      },
      "source": [
        "## 1. Main Components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HL4ROOEymiTc"
      },
      "source": [
        "### 1.1. Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLRbJPBxEQLE"
      },
      "source": [
        "#### Model - Hugging Face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhxtCSyi7YFn",
        "outputId": "9ffb0d41-9260-421c-ada0-b66159a7e47a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: huggingface_hub==0.19.4 in /usr/local/lib/python3.10/dist-packages (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.19.4) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.19.4) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.19.4) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.19.4) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.19.4) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.19.4) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.19.4) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub==0.19.4) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub==0.19.4) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub==0.19.4) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub==0.19.4) (2023.11.17)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install huggingface_hub==0.19.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-uUHYMR9-zo",
        "outputId": "1085c5dd-9a6a-4114-a5db-f23ac652a1af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "from langchain.llms import HuggingFaceHub\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = userdata.get('HUGGINGFACEHUB_API_TOKEN')\n",
        "\n",
        "repo_id = \"google/flan-t5-xxl\"  # See https://huggingface.co/models?pipeline_tag=text-generation&sort=downloads for some other options\n",
        "\n",
        "\n",
        "llm = HuggingFaceHub(\n",
        "    repo_id=repo_id, model_kwargs={\"temperature\": 0.5, \"max_length\": 64}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNJdVmW90hM0",
        "outputId": "16a0591f-ca88-4f80-ffe2-9cb230e871a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Socks for Less\n"
          ]
        }
      ],
      "source": [
        "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
        "print(llm(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhvK9K9-daNz"
      },
      "source": [
        "#### Model - Local Llama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVesRLYVlG_-",
        "outputId": "bd8680ce-50dd-4ba9-a590-e9dbfe6a81d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.2.20.tar.gz (8.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.23.5)\n",
            "Requirement already satisfied: diskcache>=5.6.1 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (5.6.3)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.20-cp310-cp310-manylinux_2_35_x86_64.whl size=1987633 sha256=c3ea7b09418d30bbe545e16384b502a46551afd36b6643e1c15e6219ad10c9a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/ef/f2/d2/0becb03047a348d7bd9a5b91ec88f4654d6fa7d67ea4e84d43\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: llama-cpp-python\n",
            "Successfully installed llama-cpp-python-0.2.20\n"
          ]
        }
      ],
      "source": [
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaSHd5PHq17E",
        "outputId": "a0861ee2-ffc3-493a-b635-6b5d2206e41f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-12-11 04:50:42--  https://gpt4all.io/models/gguf/mistral-7b-instruct-v0.1.Q4_0.gguf\n",
            "Resolving gpt4all.io (gpt4all.io)... 104.26.0.159, 104.26.1.159, 172.67.71.169, ...\n",
            "Connecting to gpt4all.io (gpt4all.io)|104.26.0.159|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4108916384 (3.8G)\n",
            "Saving to: ‘mistral-7b-instruct-v0.1.Q4_0.gguf’\n",
            "\n",
            "uct-v0.1.Q4_0.gguf   91%[=================>  ]   3.50G  70.1MB/s    eta 6s     "
          ]
        }
      ],
      "source": [
        "!wget https://gpt4all.io/models/gguf/mistral-7b-instruct-v0.1.Q4_0.gguf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "d9EoHngosUaF",
        "outputId": "83baa062-4f18-477e-f7cb-0ee72dc649de"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
          ]
        }
      ],
      "source": [
        "from langchain.llms import LlamaCpp\n",
        "\n",
        "llm = LlamaCpp(\n",
        "    model_path=\"/content/mistral-7b-instruct-v0.1.Q4_0.gguf\",\n",
        "    n_gpu_layers=200,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AjHKXtLdoGaY",
        "outputId": "85530d56-bd16-4d14-defe-7a1a584e6040"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'. We know that Neil Armstrong and Edwin \"Buzz\" Aldrin were the first two humans to walk on the moon as part of the Apollo 11 mission in July 1969. So, if we go back a generation earlier, to the Apollo 8 mission in December 1965, the first man in space was Frank R. Grissom. The first woman in space was Valentina Tereshkova in June 1963. And the first American woman in space was Sally Ride in July 1983. Now we\\'re getting close! If we go back to the early days of human flight, the Wright brothers made their first successful powered flight in December 1903. But that wasn\\'t exactly on the moon or in space. So let\\'s go further back.\\n\\nThe first man-made object to reach Earth from another celestial body was a meteorite, which is essentially space debris left behind by an asteroid or comet. Meteorites have been falling to Earth for billions of years. \\n\\nSo, the answer is: The first man on the moon was not the first human in space'"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm(\"The first man on the moon was ... Let's think step by step\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPAdlHTcEKWN"
      },
      "source": [
        "#### Model - OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "0k1ECxrM7H5L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7845051-f1ca-429a-b642-9d1a1dd1e53b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: openai==1.3.9 in /usr/local/lib/python3.10/dist-packages (1.3.9)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.9) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.3.9) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.9) (0.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.9) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.3.9) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.9) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai==1.3.9) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.3.9) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.3.9) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.3.9) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.3.9) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.3.9) (0.14.0)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install openai==1.3.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "iSa6lOIoz2kC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.llms import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# Get it from https://platform.openai.com/account/api-keys\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### LLM Model\n",
        "\n",
        "TODO: Description"
      ],
      "metadata": {
        "id": "JpFyBH7AeqLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
        "\n",
        "llm = OpenAI(temperature=0)\n",
        "print(f\"Using LLM model: {llm.model_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxa0q1Nzep8m",
        "outputId": "d04f5a08-85fd-44ce-8224-efcffd8d1ae1"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using LLM model: text-davinci-003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
        "\n",
        "print(llm(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QReKGGfgfHHJ",
        "outputId": "dcc80a19-1231-4bda-8c6f-4937e5b669e1"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Rainbow Sock Co.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Chat Model\n",
        "\n",
        "TODO: **Description**"
      ],
      "metadata": {
        "id": "NgAXDq0QfBva"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "ao51koO2FduX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdb4b561-d56f-4b8c-f2fd-26836615a158"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using chat model: gpt-3.5-turbo\n"
          ]
        }
      ],
      "source": [
        "from langchain.schema import HumanMessage\n",
        "\n",
        "chat = ChatOpenAI()\n",
        "print(f\"Using chat model: {chat.model_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [HumanMessage(content=\"What would be a good company name for a company that makes colorful socks?\")]\n",
        "\n",
        "chat(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIvIhw7Efy3I",
        "outputId": "aa08aae0-371b-471f-b739-e97ec1c41e93"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='RainbowThreads')"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjf7UO-ved4N"
      },
      "source": [
        "#### Bonus: Using LLM as a question-answering model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "l_W_MxsMeh1b"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"Question: What would be a good company name for a company that makes colorful socks?\n",
        "\n",
        "Let's think step by step.\n",
        "\n",
        "Answer: \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rie6cTv9ex9L",
        "outputId": "a0de8fcb-66a5-45fa-a174-1ca70c2c4c41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1. Brainstorm words related to socks: cozy, comfy, colorful, hosiery, foot, toes, etc.\n",
            "2. Brainstorm words related to color: vivid, bright, rainbow, spectrum, etc.\n",
            "3. Combine the two ideas: Vivid Toes, Bright Hosiery, Rainbow Socks, Colorful Comfort, etc.\n"
          ]
        }
      ],
      "source": [
        "print(llm(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShnjkqhBIXrZ"
      },
      "source": [
        "### 1.2. Prompt Templates\n",
        "\n",
        "TODO: Description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "N9HmnUcAEGyy"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"Question: {question}\n",
        "\n",
        "Let's think step by step, and then summarize the final answer in this format:\n",
        "\n",
        "Answer: \"\"\"\n",
        "\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4OBbb1iS8aN",
        "outputId": "6b85b2fa-cb59-4fb0-ed1f-c2c8bfc59130"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is a good name for a company that makes video games\n",
            "\n",
            "Let's think step by step, and then summarize the final answer in this format:\n",
            "\n",
            "Answer: \n"
          ]
        }
      ],
      "source": [
        "prompt_text = prompt.format(question=\"What is a good name for a company that makes video games\")\n",
        "print(prompt_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21brmLZKVn35",
        "outputId": "270a847b-6268-483e-a25f-82b610b241a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 1: Brainstorm words related to video games. Examples: Play, Fun, Adventure, Challenge, Create, Digital, Entertainment.\n",
            "\n",
            "Step 2: Combine words to create a unique name. Examples: Playful Entertainment, Digital Challenge, Create Adventure.\n",
            "\n",
            "Step 3: Choose the best name.\n",
            "\n",
            "Answer: Playful Entertainment.\n"
          ]
        }
      ],
      "source": [
        "print(llm(prompt_text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaorfPX0govN"
      },
      "source": [
        "### 1.3. Output Parser\n",
        "\n",
        "TODO: Description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "U8LCQLcpjhBL"
      },
      "outputs": [],
      "source": [
        "customer_review = \"\"\"\\\n",
        "This leaf blower is pretty amazing.  It has four settings:\\\n",
        "candle blower, gentle breeze, windy city, and tornado. \\\n",
        "It arrived in two days, just in time for my wife's \\\n",
        "anniversary present. \\\n",
        "I think my wife liked it so much she was speechless. \\\n",
        "So far I've been the only one using it, and I've been \\\n",
        "using it every other morning to clear the leaves on our lawn. \\\n",
        "It's slightly more expensive than the other leaf blowers \\\n",
        "out there, but I think it's worth it for the extra features.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qLVXesssbLLK"
      },
      "outputs": [],
      "source": [
        "review_template = \"\"\"\\\n",
        "For the following text, extract the following information:\n",
        "\n",
        "gift: Was the item purchased as a gift for someone else? \\\n",
        "Answer True if yes, False if not or unknown.\n",
        "\n",
        "delivery_days: How many days did it take for the product \\\n",
        "to arrive? If this information is not found, output -1.\n",
        "\n",
        "price_value: Extract any sentences about the value or price,\\\n",
        "and output them as a comma separated Python list.\n",
        "\n",
        "Format the output as JSON with the following keys:\n",
        "gift\n",
        "delivery_days\n",
        "price_value\n",
        "\n",
        "text: {text}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Ca6mcIYThGob"
      },
      "outputs": [],
      "source": [
        "prompt_template = PromptTemplate(template=review_template, input_variables=[\"text\"],)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7_8rkGmhQqL",
        "outputId": "8c96695b-7492-4246-b1ea-a082f0924114"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "{\n",
            "  \"gift\": true,\n",
            "  \"delivery_days\": 2,\n",
            "  \"price_value\": [\"slightly more expensive than the other leaf blowers out there\", \"worth it for the extra features\"]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "answer = llm(prompt_template.format(text=customer_review))\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Throw an error because answer is just a string - not dict\n",
        "answer['gift']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "THgnjFMchLKA",
        "outputId": "2ca40024-415b-4b16-f600-85eac2420a55"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-706a2f6a8b4e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Throw an error because answer is just a string - not dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gift'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AU_KoI4ClNVs"
      },
      "source": [
        "#### Using output parsers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "CpnFixOXhZrs"
      },
      "outputs": [],
      "source": [
        "from langchain.output_parsers import ResponseSchema\n",
        "from langchain.output_parsers import StructuredOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "JLIwj1odhelF"
      },
      "outputs": [],
      "source": [
        "gift_schema = ResponseSchema(name=\"gift\",\n",
        "                             description=\"Was the item purchased\\\n",
        "                             as a gift for someone else? \\\n",
        "                             Answer True if yes,\\\n",
        "                             False if not or unknown.\")\n",
        "delivery_days_schema = ResponseSchema(name=\"delivery_days\",\n",
        "                                      description=\"How many days\\\n",
        "                                      did it take for the product\\\n",
        "                                      to arrive? If this \\\n",
        "                                      information is not found,\\\n",
        "                                      output -1.\")\n",
        "price_value_schema = ResponseSchema(name=\"price_value\",\n",
        "                                    description=\"Extract any\\\n",
        "                                    sentences about the value or \\\n",
        "                                    price, and output them as a \\\n",
        "                                    comma separated Python list.\")\n",
        "\n",
        "response_schemas = [gift_schema,\n",
        "                    delivery_days_schema,\n",
        "                    price_value_schema]\n",
        "\n",
        "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAR5ZLxOhjHR",
        "outputId": "a0706f55-def1-4be5-9200-fea825ebc925"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
            "\n",
            "```json\n",
            "{\n",
            "\t\"gift\": string  // Was the item purchased                             as a gift for someone else?                              Answer True if yes,                             False if not or unknown.\n",
            "\t\"delivery_days\": string  // How many days                                      did it take for the product                                      to arrive? If this                                       information is not found,                                      output -1.\n",
            "\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a                                     comma separated Python list.\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "format_instructions = output_parser.get_format_instructions()\n",
        "print(format_instructions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "0kIknSfUjuhM"
      },
      "outputs": [],
      "source": [
        "review_template_with_instructions = \"\"\"\\\n",
        "For the following text, extract the following information:\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "text: {text}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "FCwBl5tThnYa"
      },
      "outputs": [],
      "source": [
        "prompt_template_with_output = PromptTemplate(template=review_template_with_instructions, input_variables=[\"text\"], partial_variables={\"format_instructions\": format_instructions})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "QDkxfdpgh6dl"
      },
      "outputs": [],
      "source": [
        "prompt_and_model = prompt_template_with_output | llm\n",
        "output = prompt_and_model.invoke({\"text\": customer_review})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Rgm9bZoiXp9",
        "outputId": "9d1113b7-b8cf-4ad4-cff7-86ed05f214ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'gift': 'True', 'delivery_days': '2', 'price_value': \"['slightly more expensive than the other leaf blowers out there', 'worth it for the extra features']\"}\n"
          ]
        }
      ],
      "source": [
        "# Note: Sometimes, if the model cannot extract the information, this can throw an error\n",
        "# -- which is good because we want to know early that the model cannot achieve the tasks we want it to\n",
        "\n",
        "result = output_parser.invoke(output)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5CRSY6K-ia8N",
        "outputId": "9dabc79c-047a-4015-d01b-74e41964014e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'True'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "result[\"gift\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzPkq73xlFuJ"
      },
      "source": [
        "### Bonus: Chaining Stuffs\n",
        "\n",
        "Because all of the objects implements the `Runnable` interface. It can be chained together.\n",
        "\n",
        "More info: https://python.langchain.com/docs/expression_language/why"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "FXisUIdvkvrI"
      },
      "outputs": [],
      "source": [
        "output_chain = prompt_template_with_output | llm | output_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JILirx7YlfNZ",
        "outputId": "8edfe7cc-94ad-43e9-c92c-625d13a8c1bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'gift': 'True',\n",
              " 'delivery_days': '2',\n",
              " 'price_value': \"['slightly more expensive than the other leaf blowers out there', 'worth it for the extra features']\"}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "output_chain.invoke({\"text\": customer_review})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RLhONceoZWb"
      },
      "source": [
        "## 2. Chains\n",
        "\n",
        "TODO: Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5caIbjjssPw"
      },
      "source": [
        "### Old way\n",
        "\n",
        "TODO: Description (LangChain provides a Chain object, that we can use)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPOyda-nopOm",
        "outputId": "51fe4192-463f-4e3d-a609-082c0ccd4b51"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'gift': 'True',\n",
              " 'delivery_days': '2',\n",
              " 'price_value': \"['slightly more expensive than the other leaf blowers out there', 'worth it for the extra features']\"}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "from langchain import LLMChain\n",
        "\n",
        "llm_chain = LLMChain(prompt=prompt_template_with_output, llm=llm, output_parser=output_parser)\n",
        "\n",
        "llm_chain.run(text=customer_review)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9mEHvGluJD1"
      },
      "source": [
        "### New way\n",
        "\n",
        "TODO: Description (LCEL, which allows every method to be chained by piping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0lIgnwit76G",
        "outputId": "16b6c10c-66fd-4f5c-f3dd-55dae0cff3e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'gift': 'True',\n",
              " 'delivery_days': '2',\n",
              " 'price_value': \"['slightly more expensive than the other leaf blowers out there', 'worth it for the extra features']\"}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "chain = (\n",
        " { \"text\": RunnablePassthrough() }\n",
        " | prompt_template_with_output\n",
        " | llm\n",
        " | output_parser\n",
        ")\n",
        "chain.invoke(customer_review)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJo30qgXwiAj"
      },
      "source": [
        "## 3. Memory\n",
        "\n",
        "TODO: Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opw5Oym9yNrj"
      },
      "source": [
        "### Manipulating the memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "M9dy8mE-xUGA"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "memory.chat_memory.add_user_message(\"hi!\")\n",
        "memory.chat_memory.add_ai_message(\"what's up?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DkxLtF1xj-a",
        "outputId": "29ba6ca0-41fe-4790-f8f8-cc17f841f589"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: hi!\n",
            "AI: what's up?\n"
          ]
        }
      ],
      "source": [
        "print(memory.load_memory_variables({})['history'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "NOQ9hIRrxyWn"
      },
      "outputs": [],
      "source": [
        "memory.save_context({\"input\": \"how yo doin'\"}, {\"output\": \"fine. thank you!\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFSvqBWrx12V",
        "outputId": "7b5765b1-4ae3-48e2-ce7b-c49e54437462"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: hi!\n",
            "AI: what's up?\n",
            "Human: how yo doin'\n",
            "AI: fine. thank you!\n"
          ]
        }
      ],
      "source": [
        "print(memory.load_memory_variables({})['history'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"You are a nice chatbot having a conversation with a human.\n",
        "\n",
        "New human question: {question}\n",
        "Response:\"\"\"\n",
        "prompt = PromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "HzGcpLAIS6-t"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XusFs3R6OKfs"
      },
      "source": [
        "#### Without memory"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "no_memory_chain = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=prompt,\n",
        "    verbose=False,\n",
        ")"
      ],
      "metadata": {
        "id": "0tphRLEnSoqh"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_memory_chain({\"question\": \"Hello, My name is Junior\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Yrd3V7RSshG",
        "outputId": "73d28bbe-f3f7-4a73-ff28-f7bf0d4c305d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'Hello, My name is Junior',\n",
              " 'text': ' Hi Junior, nice to meet you! How can I help you today?'}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "no_memory_chain({\"question\": \"I have just introduced myself. What is my name?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICoO_RhwTbP2",
        "outputId": "fe853728-4da3-44eb-ccec-4fedea70fee0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'I have just introduced myself. What is my name?',\n",
              " 'text': ' Nice to meet you! What is your name?'}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nB60Gvopz93e"
      },
      "source": [
        "#### With memory - LLMChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ya6BiTlNwj70"
      },
      "outputs": [],
      "source": [
        "# Notice that \"chat_history\" is present in the prompt template\n",
        "template = \"\"\"You are a nice chatbot having a conversation with a human.\n",
        "\n",
        "Previous conversation:\n",
        "{chat_history}\n",
        "\n",
        "New human question: {question}\n",
        "Response:\"\"\"\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "# Notice that we need to align the `memory_key`\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "with_memory_chain = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=prompt,\n",
        "    verbose=False,\n",
        "    memory=memory ## here - we are giving it a memory\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzznWx-iyHKX",
        "outputId": "cea45181-deb6-491c-85a0-dfe78c46cba0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'ay yo!',\n",
              " 'chat_history': '',\n",
              " 'text': ' Hi there! How can I help you?'}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "with_memory_chain({\"question\": \"ay yo!\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Za-ap-OiytQ5"
      },
      "outputs": [],
      "source": [
        "memory.save_context({\"input\": \"how yo doin' My name is Junior. Nice to meet you.\"}, {\"output\": \"Nice to meet you, Junior!. I am fine. Thank you!\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYJx4hSVzd2L",
        "outputId": "3c8ce657-f195-4473-c1a0-598c542d0726"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'what is my name again?',\n",
              " 'chat_history': \"Human: ay yo!\\nAI:  Hi there! How can I help you?\\nHuman: how yo doin' My name is Junior. Nice to meet you.\\nAI: Nice to meet you, Junior!. I am fine. Thank you!\",\n",
              " 'text': ' Your name is Junior.'}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "with_memory_chain({\"question\": \"what is my name again?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3yTC9jc0AnV"
      },
      "source": [
        "#### With memory - ConversationChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "5a-_9tWUzgCH"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import ConversationChain\n",
        "\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    verbose=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TaG9mlIH0OzQ",
        "outputId": "9a6fc393-7dea-460c-bdf8-fb9d3f2cd7b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Hi Junior, nice to meet you too! I'm doing great, thank you for asking. How about you?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "conversation.predict(input=\"how yo doin' My name is Junior. Nice to meet you.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RZ5xpupL05hb",
        "outputId": "09fdea3a-d5e4-493c-c124-948dc2f2387a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Your name is Junior. Is there anything else I can help you with?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "conversation.predict(input=\"what is my name again?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoJl3gq51Iaf"
      },
      "source": [
        "### Bonus: Different types of Memory\n",
        "\n",
        "More info: https://python.langchain.com/docs/modules/memory/types/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "_ZvHCuES1Btw"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationSummaryMemory\n",
        "\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    memory=ConversationSummaryMemory(llm=llm) # Note that the ConversationSummaryMemory will need an LLM as an input to do the summarization\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "PZpyqBUF1loI",
        "outputId": "71272d87-47f0-4251-d68a-4b15cc9631c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: how yo doin' My name is Junior. Nice to meet you.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Hi Junior, nice to meet you too! I'm doing great, thank you for asking. How about you?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "# Notice the prompt that ConversationChain format for us\n",
        "\n",
        "conversation.predict(input=\"how yo doin' My name is Junior. Nice to meet you.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "XjhU1qo01oxG",
        "outputId": "a7d1e1d9-900a-4117-ad82-cdc2c79b9dcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "The human introduces themselves as Junior and the AI responds, introducing itself and asking how Junior is doing.\n",
            "Human: I like the color red. My favorite subject is Math.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Hi Junior, I'm AI. Nice to meet you. How are you doing? I like the color red too. Math is a great subject. What do you like about it?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "conversation.predict(input=\"I like the color red. My favorite subject is Math.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "cXvbZiVa1sYe",
        "outputId": "a753d6df-a3ad-451c-a740-c7b1972e684a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "The human introduces themselves as Junior and the AI responds, introducing itself and asking how Junior is doing. Junior likes the color red and their favorite subject is Math, which the AI also likes. The AI then asks Junior what they like about Math.\n",
            "Human: Can you guess my favorite subject?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Yes, I believe your favorite subject is Math. Is that correct?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "conversation.predict(input=\"Can you guess my favorite subject?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fJb7z_02Up4"
      },
      "source": [
        "## 4. Retriever (RAG)\n",
        "\n",
        "More info: https://python.langchain.com/docs/modules/data_connection/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/hwchase17/chat-your-data/master/state_of_the_union.txt\"\n",
        "res = requests.get(url)\n",
        "with open(\"state_of_the_union.txt\", \"w\") as f:\n",
        "  f.write(res.text)"
      ],
      "metadata": {
        "id": "9mTOI-k_U5_K"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Document Loader\n",
        "from langchain.document_loaders import TextLoader\n",
        "loader = TextLoader('./state_of_the_union.txt')\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "V1RIf3JRXpmY"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Splitter\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "uFdgSU33XxCm"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Hugging Face Embeddings"
      ],
      "metadata": {
        "id": "JghPkv4NW6CZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install sentence_transformers faiss-cpu"
      ],
      "metadata": {
        "id": "kYpXyYZTXCgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "embeddings = HuggingFaceEmbeddings()"
      ],
      "metadata": {
        "id": "MFjozFrxWMTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "db = FAISS.from_documents(docs, embeddings)"
      ],
      "metadata": {
        "id": "UbQr4wpaYDaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What did the president say about Ketanji Brown Jackson\"\n",
        "docs = db.similarity_search(query)\n",
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OziBKHodYHuK",
        "outputId": "d5513687-7519-44ed-93a6-630c8cde7208"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \n",
            "\n",
            "Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n",
            "\n",
            "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
            "\n",
            "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### OpenAI Embeddings"
      ],
      "metadata": {
        "id": "d1QyqtFAW9n7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb==0.4.19 tiktoken==0.5.2"
      ],
      "metadata": {
        "id": "BZ6AcBwlXO6j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d146443b-6b0e-42b4-bbbe-5e42e24bd994"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: chromadb==0.4.19 in /usr/local/lib/python3.10/dist-packages (0.4.19)\n",
            "Requirement already satisfied: tiktoken==0.5.2 in /usr/local/lib/python3.10/dist-packages (0.5.2)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.19) (2.31.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.19) (1.10.13)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.19) (0.7.3)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.19) (0.105.0)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.19) (0.24.0.post1)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.19) (1.23.5)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.19) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.19) (4.9.0)\n",
            "Requirement already satisfied: pulsar-client>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.19) (3.3.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.19) (1.16.3)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.19) (1.21.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.19) (1.21.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.19) (0.42b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.19) (1.21.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.19) (0.15.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.19) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.19) (4.66.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.19) (7.4.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.19) (6.1.1)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.19) (1.59.3)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.19) (4.1.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.19) (0.9.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.19) (28.1.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.19) (8.2.3)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.19) (6.0.1)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.19) (4.0.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.5.2) (2023.6.3)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb==0.4.19) (3.7.1)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb==0.4.19) (0.27.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.19) (2023.11.17)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.19) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.19) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.19) (2.17.3)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.19) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.19) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.19) (3.2.2)\n",
            "Requirement already satisfied: urllib3<2.0,>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.4.19) (1.26.18)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.19) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.19) (23.5.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.19) (23.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.19) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.19) (1.12)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb==0.4.19) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb==0.4.19) (6.11.0)\n",
            "Requirement already satisfied: backoff<3.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.19) (2.2.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.19) (1.61.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.21.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.19) (1.21.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.21.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.19) (1.21.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.42b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.19) (0.42b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.42b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.19) (0.42b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.42b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.19) (0.42b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.42b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.19) (0.42b0)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.42b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.19) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.42b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.19) (1.14.1)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.42b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.4.19) (3.7.2)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb==0.4.19) (1.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb==0.4.19) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb==0.4.19) (3.6)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb==0.4.19) (0.19.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb==0.4.19) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.19) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.19) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.19) (1.0.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.19) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.19) (0.21.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.19) (12.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.95.2->chromadb==0.4.19) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.95.2->chromadb==0.4.19) (1.2.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.19) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.19) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.19) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb==0.4.19) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb==0.4.19) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==0.4.19) (3.17.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.4.19) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.4.19) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.19) (0.5.1)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "Bkshtx4tXWSj"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "c8X3UdtZT3Eu"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "db = Chroma.from_documents(docs, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What did the president say about Ketanji Brown Jackson\"\n",
        "docs = db.similarity_search(query)\n",
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXB0gcTXZhyv",
        "outputId": "e0c13aca-bc38-4d99-9918-a24f283c7adb"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \n",
            "\n",
            "Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n",
            "\n",
            "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
            "\n",
            "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Retrieval"
      ],
      "metadata": {
        "id": "RLmUHmcmX4bU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = db.as_retriever()"
      ],
      "metadata": {
        "id": "Qyn0OB_8ZFnR"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "mClNGty3cPSU"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"Answer the question based only on the following context:\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Let's think step by step.\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
        "\n",
        "\n",
        "chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2ZysBXlc2zP",
        "outputId": "e6f0ce92-0d89-4cea-87d4-4f44d148b941"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ketanji Brown Jackson is a Circuit Court of Appeals Judge who was nominated by the President 4 days ago to serve on the United States Supreme Court. She is a former top litigator in private practice, a former federal public defender, and from a family of public school educators and police officers. She has received a broad range of support from the Fraternal Order of Police to former judges appointed by Democrats and Republicans.\n"
          ]
        }
      ],
      "source": [
        "answer = chain.invoke(\"Who is Ketanji Brown Jackson?\")\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "\n",
        "langchain.debug = True\n",
        "chain.invoke(\"What does the speech say about Russia?\")\n",
        "langchain.debug = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLAe4LMMno_V",
        "outputId": "d5bbb175-5a25-4d04-d4be-cee0507f9a2b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"What does the speech say about Russia?\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"What does the speech say about Russia?\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel > 3:chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"What does the speech say about Russia?\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel > 4:chain:RunnablePassthrough] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"What does the speech say about Russia?\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel > 4:chain:RunnablePassthrough] [1ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"What does the speech say about Russia?\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel > 3:chain:RunnableSequence > 5:chain:format_docs] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel > 3:chain:RunnableSequence > 5:chain:format_docs] [0ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \\n\\nLast year COVID-19 kept us apart. This year we are finally together again. \\n\\nTonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \\n\\nWith a duty to one another to the American people to the Constitution. \\n\\nAnd with an unwavering resolve that freedom will always triumph over tyranny. \\n\\nSix days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \\n\\nHe thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \\n\\nHe met the Ukrainian people. \\n\\nFrom President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world.\\n\\nFor that purpose we’ve mobilized American ground forces, air squadrons, and ship deployments to protect NATO countries including Poland, Romania, Latvia, Lithuania, and Estonia. \\n\\nAs I have made crystal clear the United States and our Allies will defend every inch of territory of NATO countries with the full force of our collective power.  \\n\\nAnd we remain clear-eyed. The Ukrainians are fighting back with pure courage. But the next few days weeks, months, will be hard on them.  \\n\\nPutin has unleashed violence and chaos.  But while he may make gains on the battlefield – he will pay a continuing high price over the long run. \\n\\nAnd a proud Ukrainian people, who have known 30 years  of independence, have repeatedly shown that they will not tolerate anyone who tries to take their country backwards.  \\n\\nTo all Americans, I will be honest with you, as I’ve always promised. A Russian dictator, invading a foreign country, has costs around the world.\\n\\nAnd tonight I am announcing that we will join our allies in closing off American air space to all Russian flights – further isolating Russia – and adding an additional squeeze –on their economy. The Ruble has lost 30% of its value. \\n\\nThe Russian stock market has lost 40% of its value and trading remains suspended. Russia’s economy is reeling and Putin alone is to blame. \\n\\nTogether with our allies we are providing support to the Ukrainians in their fight for freedom. Military assistance. Economic assistance. Humanitarian assistance. \\n\\nWe are giving more than $1 Billion in direct assistance to Ukraine. \\n\\nAnd we will continue to aid the Ukrainian people as they defend their country and to help ease their suffering.  \\n\\nLet me be clear, our forces are not engaged and will not engage in conflict with Russian forces in Ukraine.  \\n\\nOur forces are not going to Europe to fight in Ukraine, but to defend our NATO Allies – in the event that Putin decides to keep moving west.\\n\\nWe are inflicting pain on Russia and supporting the people of Ukraine. Putin is now isolated from the world more than ever. \\n\\nTogether with our allies –we are right now enforcing powerful economic sanctions. \\n\\nWe are cutting off Russia’s largest banks from the international financial system.  \\n\\nPreventing Russia’s central bank from defending the Russian Ruble making Putin’s $630 Billion “war fund” worthless.   \\n\\nWe are choking off Russia’s access to technology that will sap its economic strength and weaken its military for years to come.  \\n\\nTonight I say to the Russian oligarchs and corrupt leaders who have bilked billions of dollars off this violent regime no more. \\n\\nThe U.S. Department of Justice is assembling a dedicated task force to go after the crimes of Russian oligarchs.  \\n\\nWe are joining with our European allies to find and seize your yachts your luxury apartments your private jets. We are coming for your ill-begotten gains.\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel > 3:chain:RunnableSequence] [182ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \\n\\nLast year COVID-19 kept us apart. This year we are finally together again. \\n\\nTonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \\n\\nWith a duty to one another to the American people to the Constitution. \\n\\nAnd with an unwavering resolve that freedom will always triumph over tyranny. \\n\\nSix days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \\n\\nHe thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \\n\\nHe met the Ukrainian people. \\n\\nFrom President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world.\\n\\nFor that purpose we’ve mobilized American ground forces, air squadrons, and ship deployments to protect NATO countries including Poland, Romania, Latvia, Lithuania, and Estonia. \\n\\nAs I have made crystal clear the United States and our Allies will defend every inch of territory of NATO countries with the full force of our collective power.  \\n\\nAnd we remain clear-eyed. The Ukrainians are fighting back with pure courage. But the next few days weeks, months, will be hard on them.  \\n\\nPutin has unleashed violence and chaos.  But while he may make gains on the battlefield – he will pay a continuing high price over the long run. \\n\\nAnd a proud Ukrainian people, who have known 30 years  of independence, have repeatedly shown that they will not tolerate anyone who tries to take their country backwards.  \\n\\nTo all Americans, I will be honest with you, as I’ve always promised. A Russian dictator, invading a foreign country, has costs around the world.\\n\\nAnd tonight I am announcing that we will join our allies in closing off American air space to all Russian flights – further isolating Russia – and adding an additional squeeze –on their economy. The Ruble has lost 30% of its value. \\n\\nThe Russian stock market has lost 40% of its value and trading remains suspended. Russia’s economy is reeling and Putin alone is to blame. \\n\\nTogether with our allies we are providing support to the Ukrainians in their fight for freedom. Military assistance. Economic assistance. Humanitarian assistance. \\n\\nWe are giving more than $1 Billion in direct assistance to Ukraine. \\n\\nAnd we will continue to aid the Ukrainian people as they defend their country and to help ease their suffering.  \\n\\nLet me be clear, our forces are not engaged and will not engage in conflict with Russian forces in Ukraine.  \\n\\nOur forces are not going to Europe to fight in Ukraine, but to defend our NATO Allies – in the event that Putin decides to keep moving west.\\n\\nWe are inflicting pain on Russia and supporting the people of Ukraine. Putin is now isolated from the world more than ever. \\n\\nTogether with our allies –we are right now enforcing powerful economic sanctions. \\n\\nWe are cutting off Russia’s largest banks from the international financial system.  \\n\\nPreventing Russia’s central bank from defending the Russian Ruble making Putin’s $630 Billion “war fund” worthless.   \\n\\nWe are choking off Russia’s access to technology that will sap its economic strength and weaken its military for years to come.  \\n\\nTonight I say to the Russian oligarchs and corrupt leaders who have bilked billions of dollars off this violent regime no more. \\n\\nThe U.S. Department of Justice is assembling a dedicated task force to go after the crimes of Russian oligarchs.  \\n\\nWe are joining with our European allies to find and seize your yachts your luxury apartments your private jets. We are coming for your ill-begotten gains.\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableParallel] [186ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"context\": \"Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \\n\\nLast year COVID-19 kept us apart. This year we are finally together again. \\n\\nTonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \\n\\nWith a duty to one another to the American people to the Constitution. \\n\\nAnd with an unwavering resolve that freedom will always triumph over tyranny. \\n\\nSix days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \\n\\nHe thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \\n\\nHe met the Ukrainian people. \\n\\nFrom President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world.\\n\\nFor that purpose we’ve mobilized American ground forces, air squadrons, and ship deployments to protect NATO countries including Poland, Romania, Latvia, Lithuania, and Estonia. \\n\\nAs I have made crystal clear the United States and our Allies will defend every inch of territory of NATO countries with the full force of our collective power.  \\n\\nAnd we remain clear-eyed. The Ukrainians are fighting back with pure courage. But the next few days weeks, months, will be hard on them.  \\n\\nPutin has unleashed violence and chaos.  But while he may make gains on the battlefield – he will pay a continuing high price over the long run. \\n\\nAnd a proud Ukrainian people, who have known 30 years  of independence, have repeatedly shown that they will not tolerate anyone who tries to take their country backwards.  \\n\\nTo all Americans, I will be honest with you, as I’ve always promised. A Russian dictator, invading a foreign country, has costs around the world.\\n\\nAnd tonight I am announcing that we will join our allies in closing off American air space to all Russian flights – further isolating Russia – and adding an additional squeeze –on their economy. The Ruble has lost 30% of its value. \\n\\nThe Russian stock market has lost 40% of its value and trading remains suspended. Russia’s economy is reeling and Putin alone is to blame. \\n\\nTogether with our allies we are providing support to the Ukrainians in their fight for freedom. Military assistance. Economic assistance. Humanitarian assistance. \\n\\nWe are giving more than $1 Billion in direct assistance to Ukraine. \\n\\nAnd we will continue to aid the Ukrainian people as they defend their country and to help ease their suffering.  \\n\\nLet me be clear, our forces are not engaged and will not engage in conflict with Russian forces in Ukraine.  \\n\\nOur forces are not going to Europe to fight in Ukraine, but to defend our NATO Allies – in the event that Putin decides to keep moving west.\\n\\nWe are inflicting pain on Russia and supporting the people of Ukraine. Putin is now isolated from the world more than ever. \\n\\nTogether with our allies –we are right now enforcing powerful economic sanctions. \\n\\nWe are cutting off Russia’s largest banks from the international financial system.  \\n\\nPreventing Russia’s central bank from defending the Russian Ruble making Putin’s $630 Billion “war fund” worthless.   \\n\\nWe are choking off Russia’s access to technology that will sap its economic strength and weaken its military for years to come.  \\n\\nTonight I say to the Russian oligarchs and corrupt leaders who have bilked billions of dollars off this violent regime no more. \\n\\nThe U.S. Department of Justice is assembling a dedicated task force to go after the crimes of Russian oligarchs.  \\n\\nWe are joining with our European allies to find and seize your yachts your luxury apartments your private jets. We are coming for your ill-begotten gains.\",\n",
            "  \"question\": \"What does the speech say about Russia?\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 6:prompt:PromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m{\n",
            "  \"context\": \"Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \\n\\nLast year COVID-19 kept us apart. This year we are finally together again. \\n\\nTonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \\n\\nWith a duty to one another to the American people to the Constitution. \\n\\nAnd with an unwavering resolve that freedom will always triumph over tyranny. \\n\\nSix days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \\n\\nHe thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \\n\\nHe met the Ukrainian people. \\n\\nFrom President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world.\\n\\nFor that purpose we’ve mobilized American ground forces, air squadrons, and ship deployments to protect NATO countries including Poland, Romania, Latvia, Lithuania, and Estonia. \\n\\nAs I have made crystal clear the United States and our Allies will defend every inch of territory of NATO countries with the full force of our collective power.  \\n\\nAnd we remain clear-eyed. The Ukrainians are fighting back with pure courage. But the next few days weeks, months, will be hard on them.  \\n\\nPutin has unleashed violence and chaos.  But while he may make gains on the battlefield – he will pay a continuing high price over the long run. \\n\\nAnd a proud Ukrainian people, who have known 30 years  of independence, have repeatedly shown that they will not tolerate anyone who tries to take their country backwards.  \\n\\nTo all Americans, I will be honest with you, as I’ve always promised. A Russian dictator, invading a foreign country, has costs around the world.\\n\\nAnd tonight I am announcing that we will join our allies in closing off American air space to all Russian flights – further isolating Russia – and adding an additional squeeze –on their economy. The Ruble has lost 30% of its value. \\n\\nThe Russian stock market has lost 40% of its value and trading remains suspended. Russia’s economy is reeling and Putin alone is to blame. \\n\\nTogether with our allies we are providing support to the Ukrainians in their fight for freedom. Military assistance. Economic assistance. Humanitarian assistance. \\n\\nWe are giving more than $1 Billion in direct assistance to Ukraine. \\n\\nAnd we will continue to aid the Ukrainian people as they defend their country and to help ease their suffering.  \\n\\nLet me be clear, our forces are not engaged and will not engage in conflict with Russian forces in Ukraine.  \\n\\nOur forces are not going to Europe to fight in Ukraine, but to defend our NATO Allies – in the event that Putin decides to keep moving west.\\n\\nWe are inflicting pain on Russia and supporting the people of Ukraine. Putin is now isolated from the world more than ever. \\n\\nTogether with our allies –we are right now enforcing powerful economic sanctions. \\n\\nWe are cutting off Russia’s largest banks from the international financial system.  \\n\\nPreventing Russia’s central bank from defending the Russian Ruble making Putin’s $630 Billion “war fund” worthless.   \\n\\nWe are choking off Russia’s access to technology that will sap its economic strength and weaken its military for years to come.  \\n\\nTonight I say to the Russian oligarchs and corrupt leaders who have bilked billions of dollars off this violent regime no more. \\n\\nThe U.S. Department of Justice is assembling a dedicated task force to go after the crimes of Russian oligarchs.  \\n\\nWe are joining with our European allies to find and seize your yachts your luxury apartments your private jets. We are coming for your ill-begotten gains.\",\n",
            "  \"question\": \"What does the speech say about Russia?\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 6:prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
            "\u001b[0m{\n",
            "  \"lc\": 1,\n",
            "  \"type\": \"constructor\",\n",
            "  \"id\": [\n",
            "    \"langchain\",\n",
            "    \"prompts\",\n",
            "    \"base\",\n",
            "    \"StringPromptValue\"\n",
            "  ],\n",
            "  \"kwargs\": {\n",
            "    \"text\": \"Answer the question based only on the following context:\\n\\nMadam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \\n\\nLast year COVID-19 kept us apart. This year we are finally together again. \\n\\nTonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \\n\\nWith a duty to one another to the American people to the Constitution. \\n\\nAnd with an unwavering resolve that freedom will always triumph over tyranny. \\n\\nSix days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \\n\\nHe thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \\n\\nHe met the Ukrainian people. \\n\\nFrom President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world.\\n\\nFor that purpose we’ve mobilized American ground forces, air squadrons, and ship deployments to protect NATO countries including Poland, Romania, Latvia, Lithuania, and Estonia. \\n\\nAs I have made crystal clear the United States and our Allies will defend every inch of territory of NATO countries with the full force of our collective power.  \\n\\nAnd we remain clear-eyed. The Ukrainians are fighting back with pure courage. But the next few days weeks, months, will be hard on them.  \\n\\nPutin has unleashed violence and chaos.  But while he may make gains on the battlefield – he will pay a continuing high price over the long run. \\n\\nAnd a proud Ukrainian people, who have known 30 years  of independence, have repeatedly shown that they will not tolerate anyone who tries to take their country backwards.  \\n\\nTo all Americans, I will be honest with you, as I’ve always promised. A Russian dictator, invading a foreign country, has costs around the world.\\n\\nAnd tonight I am announcing that we will join our allies in closing off American air space to all Russian flights – further isolating Russia – and adding an additional squeeze –on their economy. The Ruble has lost 30% of its value. \\n\\nThe Russian stock market has lost 40% of its value and trading remains suspended. Russia’s economy is reeling and Putin alone is to blame. \\n\\nTogether with our allies we are providing support to the Ukrainians in their fight for freedom. Military assistance. Economic assistance. Humanitarian assistance. \\n\\nWe are giving more than $1 Billion in direct assistance to Ukraine. \\n\\nAnd we will continue to aid the Ukrainian people as they defend their country and to help ease their suffering.  \\n\\nLet me be clear, our forces are not engaged and will not engage in conflict with Russian forces in Ukraine.  \\n\\nOur forces are not going to Europe to fight in Ukraine, but to defend our NATO Allies – in the event that Putin decides to keep moving west.\\n\\nWe are inflicting pain on Russia and supporting the people of Ukraine. Putin is now isolated from the world more than ever. \\n\\nTogether with our allies –we are right now enforcing powerful economic sanctions. \\n\\nWe are cutting off Russia’s largest banks from the international financial system.  \\n\\nPreventing Russia’s central bank from defending the Russian Ruble making Putin’s $630 Billion “war fund” worthless.   \\n\\nWe are choking off Russia’s access to technology that will sap its economic strength and weaken its military for years to come.  \\n\\nTonight I say to the Russian oligarchs and corrupt leaders who have bilked billions of dollars off this violent regime no more. \\n\\nThe U.S. Department of Justice is assembling a dedicated task force to go after the crimes of Russian oligarchs.  \\n\\nWe are joining with our European allies to find and seize your yachts your luxury apartments your private jets. We are coming for your ill-begotten gains.\\n\\nQuestion: What does the speech say about Russia?\\n\\nLet's think step by step.\\n\\nAnswer:\\n\"\n",
            "  }\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 7:llm:OpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Answer the question based only on the following context:\\n\\nMadam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \\n\\nLast year COVID-19 kept us apart. This year we are finally together again. \\n\\nTonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \\n\\nWith a duty to one another to the American people to the Constitution. \\n\\nAnd with an unwavering resolve that freedom will always triumph over tyranny. \\n\\nSix days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \\n\\nHe thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \\n\\nHe met the Ukrainian people. \\n\\nFrom President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world.\\n\\nFor that purpose we’ve mobilized American ground forces, air squadrons, and ship deployments to protect NATO countries including Poland, Romania, Latvia, Lithuania, and Estonia. \\n\\nAs I have made crystal clear the United States and our Allies will defend every inch of territory of NATO countries with the full force of our collective power.  \\n\\nAnd we remain clear-eyed. The Ukrainians are fighting back with pure courage. But the next few days weeks, months, will be hard on them.  \\n\\nPutin has unleashed violence and chaos.  But while he may make gains on the battlefield – he will pay a continuing high price over the long run. \\n\\nAnd a proud Ukrainian people, who have known 30 years  of independence, have repeatedly shown that they will not tolerate anyone who tries to take their country backwards.  \\n\\nTo all Americans, I will be honest with you, as I’ve always promised. A Russian dictator, invading a foreign country, has costs around the world.\\n\\nAnd tonight I am announcing that we will join our allies in closing off American air space to all Russian flights – further isolating Russia – and adding an additional squeeze –on their economy. The Ruble has lost 30% of its value. \\n\\nThe Russian stock market has lost 40% of its value and trading remains suspended. Russia’s economy is reeling and Putin alone is to blame. \\n\\nTogether with our allies we are providing support to the Ukrainians in their fight for freedom. Military assistance. Economic assistance. Humanitarian assistance. \\n\\nWe are giving more than $1 Billion in direct assistance to Ukraine. \\n\\nAnd we will continue to aid the Ukrainian people as they defend their country and to help ease their suffering.  \\n\\nLet me be clear, our forces are not engaged and will not engage in conflict with Russian forces in Ukraine.  \\n\\nOur forces are not going to Europe to fight in Ukraine, but to defend our NATO Allies – in the event that Putin decides to keep moving west.\\n\\nWe are inflicting pain on Russia and supporting the people of Ukraine. Putin is now isolated from the world more than ever. \\n\\nTogether with our allies –we are right now enforcing powerful economic sanctions. \\n\\nWe are cutting off Russia’s largest banks from the international financial system.  \\n\\nPreventing Russia’s central bank from defending the Russian Ruble making Putin’s $630 Billion “war fund” worthless.   \\n\\nWe are choking off Russia’s access to technology that will sap its economic strength and weaken its military for years to come.  \\n\\nTonight I say to the Russian oligarchs and corrupt leaders who have bilked billions of dollars off this violent regime no more. \\n\\nThe U.S. Department of Justice is assembling a dedicated task force to go after the crimes of Russian oligarchs.  \\n\\nWe are joining with our European allies to find and seize your yachts your luxury apartments your private jets. We are coming for your ill-begotten gains.\\n\\nQuestion: What does the speech say about Russia?\\n\\nLet's think step by step.\\n\\nAnswer:\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 7:llm:OpenAI] [2.38s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"The speech states that Russia's Vladimir Putin sought to shake the foundations of the free world, but he miscalculated. It also states that the United States and its allies are providing support to the Ukrainians in their fight for freedom, and that the United States is joining with its European allies to find and seize the assets of Russian oligarchs. The speech also states that the United States is cutting off Russia's access to technology, and is enforcing powerful economic sanctions and preventing Russia's central bank from defending the Russian Ruble. Finally, the speech states that Russia is now isolated from the world more than ever.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"Generation\"\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"prompt_tokens\": 889,\n",
            "      \"total_tokens\": 1010,\n",
            "      \"completion_tokens\": 121\n",
            "    },\n",
            "    \"model_name\": \"text-davinci-003\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence] [2.57s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"The speech states that Russia's Vladimir Putin sought to shake the foundations of the free world, but he miscalculated. It also states that the United States and its allies are providing support to the Ukrainians in their fight for freedom, and that the United States is joining with its European allies to find and seize the assets of Russian oligarchs. The speech also states that the United States is cutting off Russia's access to technology, and is enforcing powerful economic sanctions and preventing Russia's central bank from defending the Russian Ruble. Finally, the speech states that Russia is now isolated from the world more than ever.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHRKT469h7Bq"
      },
      "source": [
        "## 5. Evaluation\n",
        "\n",
        "More info: https://python.langchain.com/docs/guides/evaluation/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHwM43IToaCY"
      },
      "source": [
        "### Generating test datasets & evaluate its accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain[docarray]==0.0.349"
      ],
      "metadata": {
        "id": "1T_hTi1ke9Zj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "604dbbe9-c27d-4407-e646-a9daa2d50b34"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: langchain[docarray]==0.0.349 in /usr/local/lib/python3.10/dist-packages (0.0.349)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]==0.0.349) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]==0.0.349) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]==0.0.349) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]==0.0.349) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]==0.0.349) (0.6.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]==0.0.349) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]==0.0.349) (0.0.1)\n",
            "Requirement already satisfied: langchain-core<0.1,>=0.0.13 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]==0.0.349) (0.0.13)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]==0.0.349) (0.0.69)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]==0.0.349) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]==0.0.349) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]==0.0.349) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain[docarray]==0.0.349) (8.2.3)\n",
            "Collecting docarray[hnswlib]<0.33.0,>=0.32.0 (from langchain[docarray]==0.0.349)\n",
            "  Downloading docarray-0.32.1-py3-none-any.whl (215 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]==0.0.349) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]==0.0.349) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]==0.0.349) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]==0.0.349) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain[docarray]==0.0.349) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain[docarray]==0.0.349) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain[docarray]==0.0.349) (0.9.0)\n",
            "Collecting orjson>=3.8.2 (from docarray[hnswlib]<0.33.0,>=0.32.0->langchain[docarray]==0.0.349)\n",
            "  Downloading orjson-3.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich>=13.1.0 in /usr/local/lib/python3.10/dist-packages (from docarray[hnswlib]<0.33.0,>=0.32.0->langchain[docarray]==0.0.349) (13.7.0)\n",
            "Collecting types-requests>=2.28.11.6 (from docarray[hnswlib]<0.33.0,>=0.32.0->langchain[docarray]==0.0.349)\n",
            "  Downloading types_requests-2.31.0.10-py3-none-any.whl (14 kB)\n",
            "Collecting hnswlib>=0.6.2 (from docarray[hnswlib]<0.33.0,>=0.32.0->langchain[docarray]==0.0.349)\n",
            "  Downloading hnswlib-0.8.0.tar.gz (36 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from docarray[hnswlib]<0.33.0,>=0.32.0->langchain[docarray]==0.0.349) (3.20.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain[docarray]==0.0.349) (2.4)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.1,>=0.0.13->langchain[docarray]==0.0.349) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.1,>=0.0.13->langchain[docarray]==0.0.349) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain[docarray]==0.0.349) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain[docarray]==0.0.349) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain[docarray]==0.0.349) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain[docarray]==0.0.349) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain[docarray]==0.0.349) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain[docarray]==0.0.349) (3.0.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.1,>=0.0.13->langchain[docarray]==0.0.349) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.1,>=0.0.13->langchain[docarray]==0.0.349) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.1.0->docarray[hnswlib]<0.33.0,>=0.32.0->langchain[docarray]==0.0.349) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.1.0->docarray[hnswlib]<0.33.0,>=0.32.0->langchain[docarray]==0.0.349) (2.16.1)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain[docarray]==0.0.349)\n",
            "  Downloading urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.6/104.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain[docarray]==0.0.349) (1.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->docarray[hnswlib]<0.33.0,>=0.32.0->langchain[docarray]==0.0.349) (0.1.2)\n",
            "Building wheels for collected packages: hnswlib\n",
            "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hnswlib: filename=hnswlib-0.8.0-cp310-cp310-linux_x86_64.whl size=2287670 sha256=348800f9644c994ef44928a06b55d640791706cffaa3b4238b819afdc764cd61\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/a9/3e/3e5d59ee41664eb31a4e6de67d1846f86d16d93c45f277c4e7\n",
            "Successfully built hnswlib\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: urllib3, orjson, hnswlib, types-requests, docarray\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.18\n",
            "    Uninstalling urllib3-1.26.18:\n",
            "      Successfully uninstalled urllib3-1.26.18\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kubernetes 28.1.0 requires urllib3<2.0,>=1.24.2, but you have urllib3 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed docarray-0.32.1 hnswlib-0.8.0 orjson-3.9.10 types-requests-2.31.0.10 urllib3-2.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "hnswlib"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "RvTqau3jloYq"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/Ryota-Kawamura/LangChain-for-LLM-Application-Development/main/OutdoorClothingCatalog_1000.csv\"\n",
        "res = requests.get(url)\n",
        "with open(\"OutdoorClothingCatalog_1000.csv\", \"w\") as f:\n",
        "  f.write(res.text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai_llm = OpenAI(temperature=0)\n",
        "hf_llm = HuggingFaceHub(\n",
        "    repo_id=repo_id, model_kwargs={\"temperature\": 0.5, \"max_length\": 64}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyjx4jauhXrt",
        "outputId": "7da3a06c-c82a-4051-a706-1d7a380e5bc7"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import CSVLoader\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.vectorstores import DocArrayInMemorySearch\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "file = \"./OutdoorClothingCatalog_1000.csv\"\n",
        "loader = CSVLoader(file_path=file)\n",
        "data = loader.load()\n",
        "\n",
        "index = VectorstoreIndexCreator(\n",
        "    vectorstore_cls=DocArrayInMemorySearch\n",
        ").from_loaders([loader])"
      ],
      "metadata": {
        "id": "Si1tJCVteEQj"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoxCSYgVe3dD",
        "outputId": "c544befb-4950-482a-d9a2-5a44cdbcdc02"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content=\": 10\\nname: Cozy Comfort Pullover Set, Stripe\\ndescription: Perfect for lounging, this striped knit set lives up to its name. We used ultrasoft fabric and an easy design that's as comfortable at bedtime as it is when we have to make a quick run out.\\n\\nSize & Fit\\n- Pants are Favorite Fit: Sits lower on the waist.\\n- Relaxed Fit: Our most generous fit sits farthest from the body.\\n\\nFabric & Care\\n- In the softest blend of 63% polyester, 35% rayon and 2% spandex.\\n\\nAdditional Features\\n- Relaxed fit top with raglan sleeves and rounded hem.\\n- Pull-on pants have a wide elastic waistband and drawstring, side pockets and a modern slim leg.\\n\\nImported.\", metadata={'source': './OutdoorClothingCatalog_1000.csv', 'row': 10})"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[11]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_47vzo7fwM4",
        "outputId": "88e60591-ab5c-46e6-8861-b20f8852313b"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content=': 11\\nname: Ultra-Lofty 850 Stretch Down Hooded Jacket\\ndescription: This technical stretch down jacket from our DownTek collection is sure to keep you warm and comfortable with its full-stretch construction providing exceptional range of motion. With a slightly fitted style that falls at the hip and best with a midweight layer, this jacket is suitable for light activity up to 20° and moderate activity up to -30°. The soft and durable 100% polyester shell offers complete windproof protection and is insulated with warm, lofty goose down. Other features include welded baffles for a no-stitch construction and excellent stretch, an adjustable hood, an interior media port and mesh stash pocket and a hem drawcord. Machine wash and dry. Imported.', metadata={'source': './OutdoorClothingCatalog_1000.csv', 'row': 11})"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_examples = [\n",
        "    {\n",
        "        \"query\": \"Do the Cozy Comfort Pullover Set\\\n",
        "        have side pockets?\",\n",
        "        \"answer\": \"Yes\"\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"What collection is the Ultra-Lofty \\\n",
        "        850 Stretch Down Hooded Jacket from?\",\n",
        "        \"answer\": \"The DownTek collection\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# But how can we automate the generation of these questions & answers ? (:thinking:)"
      ],
      "metadata": {
        "id": "7dV3rGhVfxB1"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.evaluation.qa import QAGenerateChain\n",
        "\n",
        "example_gen_chain = QAGenerateChain.from_llm(ChatOpenAI())"
      ],
      "metadata": {
        "id": "tEp0xsCtf0Ik"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_examples = example_gen_chain.apply_and_parse(\n",
        "    [{\"doc\": t} for t in data[:5]]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Af_JA1WfhhWJ",
        "outputId": "d33bb9c5-8e2d-409a-b281-71f25d318bc8"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:344: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_examples[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jZ8AKK4h6wb",
        "outputId": "b015efbd-f99a-4718-f05c-69a482e0beb2"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'qa_pairs': {'query': \"What is the weight of one pair of Women's Campside Oxfords?\",\n",
              "  'answer': \"The approximate weight of one pair of Women's Campside Oxfords is 1 lb. 1 oz.\"}}"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIQqoKuQh8-G",
        "outputId": "70555b87-3b96-4958-b610-fdff5514ee08"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content=\": 0\\nname: Women's Campside Oxfords\\ndescription: This ultracomfortable lace-to-toe Oxford boasts a super-soft canvas, thick cushioning, and quality construction for a broken-in feel from the first time you put them on. \\n\\nSize & Fit: Order regular shoe size. For half sizes not offered, order up to next whole size. \\n\\nSpecs: Approx. weight: 1 lb.1 oz. per pair. \\n\\nConstruction: Soft canvas material for a broken-in feel and look. Comfortable EVA innersole with Cleansport NXT® antimicrobial odor control. Vintage hunt, fish and camping motif on innersole. Moderate arch contour of innersole. EVA foam midsole for cushioning and support. Chain-tread-inspired molded rubber outsole with modified chain-tread pattern. Imported. \\n\\nQuestions? Please contact us for any inquiries.\", metadata={'source': './OutdoorClothingCatalog_1000.csv', 'row': 0})"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model under test\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=hf_llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=index.vectorstore.as_retriever(),\n",
        "    verbose=True,\n",
        "    chain_type_kwargs = {\n",
        "        \"document_separator\": \"<<<<>>>>>\"\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "8_CIzYLOlMRN"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa.run(test_data_examples[0][\"query\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "bqA3wlITiSg0",
        "outputId": "9f14c09b-dfb3-4de3-c3f1-e756604652c3"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'yes'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = []\n",
        "for example in generated_examples:\n",
        "  test_data.append(example['qa_pairs'])\n",
        "\n",
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcHEKKW3l0dn",
        "outputId": "b641791d-b5e2-49cf-9263-8a5ee871e323"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'query': \"What is the weight of one pair of Women's Campside Oxfords?\",\n",
              "  'answer': \"The approximate weight of one pair of Women's Campside Oxfords is 1 lb. 1 oz.\"},\n",
              " {'query': 'What are the dimensions of the small and medium sizes of the Recycled Waterhog Dog Mat, Chevron Weave?',\n",
              "  'answer': 'The small size of the Recycled Waterhog Dog Mat, Chevron Weave has dimensions of 18\" x 28\", while the medium size has dimensions of 22.5\" x 34.5\".'},\n",
              " {'query': \"What are some features of the Infant and Toddler Girls' Coastal Chill Swimsuit, Two-Piece?\",\n",
              "  'answer': \"Some features of the Infant and Toddler Girls' Coastal Chill Swimsuit, Two-Piece include bright colors, ruffles, exclusive whimsical prints, four-way-stretch and chlorine-resistant fabric, UPF 50+ rated fabric for sun protection, crossover no-slip straps, fully lined bottom for a secure fit and maximum coverage, and it can be machine washed and line dried for best results.\"},\n",
              " {'query': \"What is the composition of the swimtop's fabric?\",\n",
              "  'answer': 'The swimtop is made of 82% recycled nylon and 18% Lycra® spandex.'},\n",
              " {'query': 'What is the main feature of the EcoFlex 3L Storm Pants?',\n",
              "  'answer': 'The main feature of the EcoFlex 3L Storm Pants is the TEK O2 technology, which provides enhanced breathability.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = qa.apply(test_data)\n",
        "predictions"
      ],
      "metadata": {
        "id": "Ej5kBYpYiyfw",
        "outputId": "a649e723-d600-4736-ec57-5ce65c64e9a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'query': \"What is the weight of one pair of Women's Campside Oxfords?\",\n",
              "  'answer': \"The approximate weight of one pair of Women's Campside Oxfords is 1 lb. 1 oz.\",\n",
              "  'result': '1 lb.1 oz.'},\n",
              " {'query': 'What are the dimensions of the small and medium sizes of the Recycled Waterhog Dog Mat, Chevron Weave?',\n",
              "  'answer': 'The small size of the Recycled Waterhog Dog Mat, Chevron Weave has dimensions of 18\" x 28\", while the medium size has dimensions of 22.5\" x 34.5\".',\n",
              "  'result': '18\" x 28\" and 22.5\" x 34.5\"'},\n",
              " {'query': \"What are some features of the Infant and Toddler Girls' Coastal Chill Swimsuit, Two-Piece?\",\n",
              "  'answer': \"Some features of the Infant and Toddler Girls' Coastal Chill Swimsuit, Two-Piece include bright colors, ruffles, exclusive whimsical prints, four-way-stretch and chlorine-resistant fabric, UPF 50+ rated fabric for sun protection, crossover no-slip straps, fully lined bottom for a secure fit and maximum coverage, and it can be machine washed and line dried for best results.\",\n",
              "  'result': \"The four-way-stretch and chlorine-resistant fabric keeps its shape and resists snags. The UPF 50+ rated fabric provides the highest rated sun protection possible, blocking 98% of the sun's harmful rays. The crossover no-slip straps and fully lined bottom ensure a secure fit and maximum coverage. Machine wash and line dry for best results. Imported.>>>>>\"},\n",
              " {'query': \"What is the composition of the swimtop's fabric?\",\n",
              "  'answer': 'The swimtop is made of 82% recycled nylon and 18% Lycra® spandex.',\n",
              "  'result': '80% nylon, 20% Lycra Xtra Life fiber.'},\n",
              " {'query': 'What is the main feature of the EcoFlex 3L Storm Pants?',\n",
              "  'answer': 'The main feature of the EcoFlex 3L Storm Pants is the TEK O2 technology, which provides enhanced breathability.',\n",
              "  'result': \"It's guaranteed to keep you dry and comfortable – whatever the activity and whatever the weather.\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`answer` is the actual answer expected from the question\n",
        "\n",
        "`result` is what model under test predicts\n",
        "\n",
        "Notice that the `answer` and the `result` is not an exact 1-to-1 match, BUT the content could be saying the same thing.\n",
        "\n",
        "This is why we need **ANOTHER** LLM model to help evaluate whether the answer and the predicted result is saying the same thing."
      ],
      "metadata": {
        "id": "Gy1i0dv8ukr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.evaluation.qa import QAEvalChain\n",
        "\n",
        "eval_chain = QAEvalChain.from_llm(openai_llm)"
      ],
      "metadata": {
        "id": "uN6aBWrdi0Zc"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graded_outputs = eval_chain.evaluate(test_data, predictions)"
      ],
      "metadata": {
        "id": "3gSfsPaGmr1A"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graded_outputs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nK7Z5_Fm2ve",
        "outputId": "7e6c37ce-9b7c-41fc-e3b9-0a42a9804d40"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'results': ' CORRECT'}"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, eg in enumerate(generated_examples):\n",
        "    print(f\"Example {i}:\")\n",
        "    print(\"Question: \" + predictions[i]['query'])\n",
        "    print(\"Real Answer: \" + predictions[i]['answer'])\n",
        "    print(\"Predicted Answer: \" + predictions[i]['result'])\n",
        "    print('Verdict: ' + graded_outputs[i]['results'])\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14r0SlAJmxxH",
        "outputId": "e6845299-4083-4ca4-8e42-7f7ff312996f"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 0:\n",
            "Question: What is the weight of one pair of Women's Campside Oxfords?\n",
            "Real Answer: The approximate weight of one pair of Women's Campside Oxfords is 1 lb. 1 oz.\n",
            "Predicted Answer: 1 lb.1 oz.\n",
            "Verdict:  CORRECT\n",
            "\n",
            "Example 1:\n",
            "Question: What are the dimensions of the small and medium sizes of the Recycled Waterhog Dog Mat, Chevron Weave?\n",
            "Real Answer: The small size of the Recycled Waterhog Dog Mat, Chevron Weave has dimensions of 18\" x 28\", while the medium size has dimensions of 22.5\" x 34.5\".\n",
            "Predicted Answer: 18\" x 28\" and 22.5\" x 34.5\"\n",
            "Verdict:  CORRECT\n",
            "\n",
            "Example 2:\n",
            "Question: What are some features of the Infant and Toddler Girls' Coastal Chill Swimsuit, Two-Piece?\n",
            "Real Answer: Some features of the Infant and Toddler Girls' Coastal Chill Swimsuit, Two-Piece include bright colors, ruffles, exclusive whimsical prints, four-way-stretch and chlorine-resistant fabric, UPF 50+ rated fabric for sun protection, crossover no-slip straps, fully lined bottom for a secure fit and maximum coverage, and it can be machine washed and line dried for best results.\n",
            "Predicted Answer: The four-way-stretch and chlorine-resistant fabric keeps its shape and resists snags. The UPF 50+ rated fabric provides the highest rated sun protection possible, blocking 98% of the sun's harmful rays. The crossover no-slip straps and fully lined bottom ensure a secure fit and maximum coverage. Machine wash and line dry for best results. Imported.>>>>>\n",
            "Verdict:  CORRECT\n",
            "\n",
            "Example 3:\n",
            "Question: What is the composition of the swimtop's fabric?\n",
            "Real Answer: The swimtop is made of 82% recycled nylon and 18% Lycra® spandex.\n",
            "Predicted Answer: 80% nylon, 20% Lycra Xtra Life fiber.\n",
            "Verdict:  CORRECT\n",
            "\n",
            "Example 4:\n",
            "Question: What is the main feature of the EcoFlex 3L Storm Pants?\n",
            "Real Answer: The main feature of the EcoFlex 3L Storm Pants is the TEK O2 technology, which provides enhanced breathability.\n",
            "Predicted Answer: It's guaranteed to keep you dry and comfortable – whatever the activity and whatever the weather.\n",
            "Verdict:  CORRECT\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bonus: Evaluator"
      ],
      "metadata": {
        "id": "pEVhSc0knNhD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3JHYSlWls-T",
        "outputId": "abb1679b-beea-443e-d950-2762b286644b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation value (Y/N): N\n",
            "Evaluation score: 0\n",
            "Evaluation reasoning: The criterion is conciseness, which means the submission should be brief and to the point. \n",
            "\n",
            "Looking at the submission, the answer to the question \"What's 2+2?\" is given as \"The answer you're looking for is that two and two is four.\" However, before providing the answer, the respondent adds an unnecessary comment: \"That's an elementary question.\" This comment does not contribute to answering the question and thus makes the response less concise.\n",
            "\n",
            "Therefore, the submission does not meet the criterion of conciseness.\n",
            "\n",
            "N\n"
          ]
        }
      ],
      "source": [
        "from langchain.evaluation import load_evaluator\n",
        "from langchain.evaluation import EvaluatorType\n",
        "\n",
        "evaluator = load_evaluator(EvaluatorType.CRITERIA, criteria=\"conciseness\")\n",
        "\n",
        "eval_result = evaluator.evaluate_strings(\n",
        "    prediction=\"What's 2+2? That's an elementary question. The answer you're looking for is that two and two is four.\",\n",
        "    input=\"What's 2+2?\",\n",
        ")\n",
        "\n",
        "print(f'Evaluation value (Y/N): {eval_result[\"value\"]}')\n",
        "print(f'Evaluation score: {eval_result[\"score\"]}')\n",
        "print(f'Evaluation reasoning: {eval_result[\"reasoning\"]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgEmosCPQHXO",
        "outputId": "7e1962f6-4c0c-4368-fbf2-97239defe139"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation value (Y/N): Y\n",
            "Evaluation score: 1\n",
            "Evaluation reasoning: The criterion is conciseness, which means the submission should be brief and to the point. \n",
            "\n",
            "Looking at the submission, the answer to the question \"What's 2+2?\" is given as \"four.\" This is a direct and succinct response to the question. \n",
            "\n",
            "The submission does not include any unnecessary information or details, making it concise. \n",
            "\n",
            "Therefore, the submission meets the criterion of conciseness. \n",
            "\n",
            "Y\n"
          ]
        }
      ],
      "source": [
        "eval_result = evaluator.evaluate_strings(\n",
        "    prediction=\"four.\",\n",
        "    input=\"What's 2+2?\",\n",
        ")\n",
        "\n",
        "print(f'Evaluation value (Y/N): {eval_result[\"value\"]}')\n",
        "print(f'Evaluation score: {eval_result[\"score\"]}')\n",
        "print(f'Evaluation reasoning: {eval_result[\"reasoning\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mixWcScRCc9"
      },
      "source": [
        "#### Different type of evaluator -- Labeled Criteria"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2j_Cx1UQmNf_",
        "outputId": "7cc457f6-4fe6-46b6-e8d5-0608abf457a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation value (Y/N): N\n",
            "Evaluation score: 0\n",
            "Evaluation reasoning: The criterion for this task is the correctness of the submitted answer. The input asks for the capital of the US. The submitted answer is \"Bangkok\", which is incorrect as the capital of the US is Washington D.C., as stated in the reference. Therefore, the submission does not meet the criterion of correctness.\n",
            "\n",
            "N\n"
          ]
        }
      ],
      "source": [
        "evaluator = load_evaluator(\"labeled_criteria\", criteria=\"correctness\")\n",
        "\n",
        "# We can even override the model's learned knowledge using ground truth labels\n",
        "eval_result = evaluator.evaluate_strings(\n",
        "    input=\"What is the capital of the US?\",\n",
        "    prediction=\"Bangkok\",\n",
        "    reference=\"The capital of the US is Washington D.C.\",\n",
        ")\n",
        "\n",
        "print(f'Evaluation value (Y/N): {eval_result[\"value\"]}')\n",
        "print(f'Evaluation score: {eval_result[\"score\"]}')\n",
        "print(f'Evaluation reasoning: {eval_result[\"reasoning\"]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXLfgyq9QQQ-",
        "outputId": "027a6845-911d-46a9-ca1f-e8c53ecfe49f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation value (Y/N): Y\n",
            "Evaluation score: 1\n",
            "Evaluation reasoning: The criterion for this task is the correctness of the submitted answer. This involves checking if the submission is accurate, factual, and directly answers the given input.\n",
            "\n",
            "The input asks for the capital of the US. The submitted answer is Washington D.C.\n",
            "\n",
            "Comparing this with the reference answer, which is also Washington D.C., it is clear that the submitted answer is correct. It is factual and accurate, as Washington D.C. is indeed the capital of the US.\n",
            "\n",
            "Therefore, the submission meets the criterion.\n",
            "\n",
            "Y\n"
          ]
        }
      ],
      "source": [
        "evaluator = load_evaluator(\"labeled_criteria\", criteria=\"correctness\")\n",
        "\n",
        "# We can even override the model's learned knowledge using ground truth labels\n",
        "eval_result = evaluator.evaluate_strings(\n",
        "    input=\"What is the capital of the US?\",\n",
        "    prediction=\"Washington D.C.\",\n",
        "    reference=\"The capital of the US is Washington D.C.\",\n",
        ")\n",
        "\n",
        "print(f'Evaluation value (Y/N): {eval_result[\"value\"]}')\n",
        "print(f'Evaluation score: {eval_result[\"score\"]}')\n",
        "print(f'Evaluation reasoning: {eval_result[\"reasoning\"]}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "eitV0BpiDiWE",
        "gLRbJPBxEQLE",
        "RhvK9K9-daNz",
        "nPAdlHTcEKWN",
        "JpFyBH7AeqLm",
        "NgAXDq0QfBva",
        "jjf7UO-ved4N",
        "ShnjkqhBIXrZ",
        "TaorfPX0govN",
        "wzPkq73xlFuJ",
        "0RLhONceoZWb",
        "JJo30qgXwiAj",
        "2fJb7z_02Up4",
        "JghPkv4NW6CZ",
        "rHwM43IToaCY",
        "pEVhSc0knNhD"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}